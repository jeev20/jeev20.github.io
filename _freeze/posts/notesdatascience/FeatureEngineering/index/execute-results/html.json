{
  "hash": "fbf2015ed2bc0535be3f591f138e2c84",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Feature engineering\nformat: html\ntoc: true\nlang: en\njupyter: python3\nipynb-shell-interactivity: all\nexecute:\n  echo: false\ndate: 2025-08-09 14:02 +0200\ncategories: [\"datascience\", \"fundamentals\"]\ntags: [\"notes\", \"featureengineering\"]\ncomments:\n  giscus:\n    repo: jeev20/jeev20.github.io\n---\n\n\n\n# Feature engineering\n\nThis is my notes on feature engineering. The idea is to populate this article with all possible relevant knowledge I can get on my hands on and then use it as a reference in the future. Plan is also to use what I Study and note once, use many times.\n\n```{mermaid}\nmindmap\n  root((Feature engineering))\n    Feature transformation\n        Handling missing values\n            Imputation\n                Remove observation\n                Mean replacement\n                Median replacement\n                Most frequest categorical\n        Handling categorical values\n            One-hot-encoding\n            Binning\n        Handling outliers\n            Outlier detection\n            Outlier removal\n        Feature scaling\n            Standardization\n            Normalization\n    Feature construction\n        Domain knowledge\n        Experience\n    Feature selection\n        Feature importance \n    Feature extraction\n```\n\n::: {#cc5a7763 .cell execution_count=1}\n``` {.python .cell-code}\nimport polars as pl\ninput_data_path = f\"../data/iot/iot_telemetry_data.parquet\"\ndf_original =  pl.read_parquet(input_data_path)\ndf_original.head(1)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>device</th><th>co</th><th>humidity</th><th>light</th><th>lpg</th><th>motion</th><th>smoke</th><th>temp</th></tr><tr><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>bool</td><td>f64</td><td>bool</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.5945e9</td><td>&quot;b8:27:eb:bf:9d:51&quot;</td><td>0.004956</td><td>51.0</td><td>false</td><td>0.007651</td><td>false</td><td>0.020411</td><td>22.7</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## 1. Feature transformation\n\n## Importing modules\n\n::: {#743c9d72 .cell execution_count=2}\n``` {.python .cell-code}\nimport duckdb\nimport polars as pl\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Reading data\n\n::: {#14d1890b .cell execution_count=3}\n``` {.python .cell-code}\n# ts is in epoch time format so converting it to timestamp\n# rounding values for temperature and humidity\n# converting temperature from farhaneit to celsius\ndf_raw = duckdb.sql(\n    f\"SELECT ts, to_timestamp(ts) AS timestamp, device, temp,ROUND((temp - 32) * 5.0 / 9, 4) AS temp_c, ROUND(humidity, 4) AS humidity, lpg, smoke, light FROM '{input_data_path}'\"\n)\n```\n:::\n\n\n## Exploring the data\nThe seven questions to get insight into the data \n\n### How big is the data? \n\n::: {#27477c2d .cell execution_count=4}\n``` {.python .cell-code}\n# Converting to polars to easy statistics and exploration\ndf_original = df_raw.pl()  \ndf_original.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\n(405184, 9)\n```\n:::\n:::\n\n\n### Imputation / Handling missing values\n\nThis dataset is quiet clean, there are no missing data in the input data in any feature. [Docs Reference](https://docs.pola.rs/user-guide/expressions/missing-data/)\n\n::: {#ac9c28d9 .cell execution_count=5}\n``` {.python .cell-code}\ndf_original.null_count()\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>timestamp</th><th>device</th><th>temp</th><th>temp_c</th><th>humidity</th><th>lpg</th><th>smoke</th><th>light</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Handling categorical variables\n\n### Outlier detection\n\n### Feature scaling\n\n\n### Datetime transformation\n\nThe `ts` column is in unix seconds, which we will convert to timestamp.\n\n::: {#7d9bb44e .cell execution_count=6}\n``` {.python .cell-code}\ndf_original = df_original.with_columns(pl.from_epoch(pl.col(\"ts\"), time_unit=\"s\").alias(\"timestamp\"))\ndf_original.head(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>timestamp</th><th>device</th><th>temp</th><th>temp_c</th><th>humidity</th><th>lpg</th><th>smoke</th><th>light</th></tr><tr><td>f64</td><td>datetime[μs]</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>1.5945e9</td><td>2020-07-12 00:01:34</td><td>&quot;b8:27:eb:bf:9d:51&quot;</td><td>22.7</td><td>-5.1667</td><td>51.0</td><td>0.007651</td><td>0.020411</td><td>false</td></tr><tr><td>1.5945e9</td><td>2020-07-12 00:01:34</td><td>&quot;00:0f:00:70:91:0a&quot;</td><td>19.700001</td><td>-6.8333</td><td>76.0</td><td>0.005114</td><td>0.013275</td><td>false</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n#### What is the date range of the data collected?\n\nThe time range of the dataset is\n\n::: {#b3c730bb .cell execution_count=7}\n``` {.python .cell-code}\nprint(df_original.select(pl.col(['timestamp', 'ts'])).describe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (9, 3)\n┌────────────┬────────────────────────────┬───────────────┐\n│ statistic  ┆ timestamp                  ┆ ts            │\n│ ---        ┆ ---                        ┆ ---           │\n│ str        ┆ str                        ┆ f64           │\n╞════════════╪════════════════════════════╪═══════════════╡\n│ count      ┆ 405184                     ┆ 405184.0      │\n│ null_count ┆ 0                          ┆ 0.0           │\n│ mean       ┆ 2020-07-16 00:06:56.798528 ┆ 1.5949e9      │\n│ std        ┆ null                       ┆ 199498.399262 │\n│ min        ┆ 2020-07-12 00:01:34        ┆ 1.5945e9      │\n│ 25%        ┆ 2020-07-14 00:20:00        ┆ 1.5947e9      │\n│ 50%        ┆ 2020-07-16 00:06:28        ┆ 1.5949e9      │\n│ 75%        ┆ 2020-07-18 00:02:56        ┆ 1.5950e9      │\n│ max        ┆ 2020-07-20 00:03:37        ┆ 1.5952e9      │\n└────────────┴────────────────────────────┴───────────────┘\n```\n:::\n:::\n\n\n#### Find the average humidity level across all sensors.\n\n::: {#f5b3d884 .cell execution_count=8}\n``` {.python .cell-code}\ndf_original.select(pl.col(\"humidity\").mean())\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>humidity</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>60.511694</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Remove unwanted columns\n\nWe are only interested in certain columns, the rest of the columns can be removed.\n\n::: {#c174a821 .cell execution_count=9}\n``` {.python .cell-code}\nirrelevant_columns = [\"co\", \"lpg\", \"motion\", \"smoke\", \"ts\", \"light\"]\nfor columnname in irrelevant_columns:\n    pass\n    #df = df_original.drop(columnname)\n#df_original.head(1)\n```\n:::\n\n\n### Reorganize the columns\n\n::: {#3416662a .cell execution_count=10}\n``` {.python .cell-code}\ndf = df_original.select(['timestamp', 'device', 'temp', 'humidity'])\ndf = df.sort(by=\"timestamp\")\ndf.head(1)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>device</th><th>temp</th><th>humidity</th></tr><tr><td>datetime[μs]</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2020-07-12 00:01:34</td><td>&quot;b8:27:eb:bf:9d:51&quot;</td><td>22.7</td><td>51.0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#2f311efb .cell execution_count=11}\n``` {.python .cell-code}\nimport seaborn as sn\nsn.lineplot(df.head(100), x=\"timestamp\", y=\"temp\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=585 height=429}\n:::\n:::\n\n\n::: {#a15fb381 .cell execution_count=12}\n``` {.python .cell-code}\nfrom prophet import Prophet\nimport pandas as pd\nimport dyplot\ndf_device_1 = df.filter(pl.col(\"device\")==\"b8:27:eb:bf:9d:51\")\ndf_device_2 = df.filter(pl.col(\"device\")==\"00:0f:00:70:91:0a\")\ndf_device_3 = df.filter(pl.col(\"device\")==\"1c:bf:ce:15:ec:4d\")\n\n\ndef get_forecast_data(df):\n    device_df = df.select(pl.col([\"timestamp\", \"temp\"])).rename({\"timestamp\":\"ds\", \"temp\":\"y\"})\n    device_df = device_df.to_pandas()\n    m = Prophet()\n    m.fit(device_df)\n\n    future = m.make_future_dataframe(periods=4)\n    forecast = m.predict(future)\n    forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n    fig = m.plot(forecast)\n    fig_comp = m.plot_components(forecast)\n    #fig_dyplot = dyplot.prophet(m, forecast)\n    #fig_dyplot.show()\n    return fig, fig_comp\n\nfig, fig_comp = get_forecast_data(df_device_1)\nfig, fig_comp = get_forecast_data(df_device_2)\nfig, fig_comp = get_forecast_data(df_device_3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n21:45:04 - cmdstanpy - INFO - Chain [1] start processing\n21:46:24 - cmdstanpy - INFO - Chain [1] done processing\n21:46:45 - cmdstanpy - INFO - Chain [1] start processing\n21:47:28 - cmdstanpy - INFO - Chain [1] done processing\n21:47:41 - cmdstanpy - INFO - Chain [1] start processing\n21:48:40 - cmdstanpy - INFO - Chain [1] done processing\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-2.png){width=945 height=566}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-3.png){width=849 height=566}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-4.png){width=945 height=566}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-5.png){width=849 height=566}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-6.png){width=945 height=566}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-7.png){width=849 height=566}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}