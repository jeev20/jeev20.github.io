{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Feature engineering\n",
        "description: \"Understanding how to perform feature engineering\"\n",
        "format: html\n",
        "toc: true\n",
        "lang: en\n",
        "jupyter: python3\n",
        "ipynb-shell-interactivity: all\n",
        "execute:\n",
        "  echo: false\n",
        "date: 2025-08-09 14:02 +0200\n",
        "categories: [\"datascience\", \"fundamentals\"]\n",
        "tags: [\"notes\", \"featureengineering\"]\n",
        "comments:\n",
        "  giscus:\n",
        "    repo: jeev20/jeev20.github.io\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Feature engineering\n",
        "\n",
        "This is my notes on feature engineering. The idea is to populate this article with all possible relevant knowledge I can get on my hands on and then use it as a reference in the future. Plan is also to use what I Study and note once, use many times.\n",
        "\n",
        "```{mermaid}\n",
        "mindmap\n",
        "  root((Feature engineering))\n",
        "    Feature transformation\n",
        "        Handling missing values\n",
        "            Imputation\n",
        "                Remove observation\n",
        "                Mean replacement\n",
        "                Median replacement\n",
        "                Most frequest categorical\n",
        "        Handling categorical values\n",
        "            One-hot-encoding\n",
        "            Binning\n",
        "        Handling outliers\n",
        "            Outlier detection\n",
        "            Outlier removal\n",
        "        Feature scaling\n",
        "            Standardization\n",
        "            Normalization\n",
        "    Feature construction\n",
        "        Domain knowledge\n",
        "        Experience\n",
        "    Feature selection\n",
        "        Feature importance \n",
        "    Feature extraction\n",
        "```"
      ],
      "id": "6b04bbe6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import polars as pl\n",
        "input_data_path = f\"../data/iot/iot_telemetry_data.parquet\"\n",
        "df_original =  pl.read_parquet(input_data_path)\n",
        "df_original.head(1)"
      ],
      "id": "96937fdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Feature transformation\n",
        "\n",
        "## Importing modules"
      ],
      "id": "a76f2693"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "import duckdb\n",
        "import polars as pl\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "b7be899b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading data"
      ],
      "id": "7d10d115"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# ts is in epoch time format so converting it to timestamp\n",
        "# rounding values for temperature and humidity\n",
        "# converting temperature from farhaneit to celsius\n",
        "df_raw = duckdb.sql(\n",
        "    f\"SELECT ts, to_timestamp(ts) AS timestamp, device, temp,ROUND((temp - 32) * 5.0 / 9, 4) AS temp_c, ROUND(humidity, 4) AS humidity, lpg, smoke, light FROM '{input_data_path}'\"\n",
        ")"
      ],
      "id": "f1a1542b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring the data\n",
        "The seven questions to get insight into the data \n",
        "\n",
        "### How big is the data? "
      ],
      "id": "19377a68"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# Converting to polars to easy statistics and exploration\n",
        "df_original = df_raw.pl()  \n",
        "df_original.shape"
      ],
      "id": "7c4e1091",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputation / Handling missing values\n",
        "\n",
        "This dataset is quiet clean, there are no missing data in the input data in any feature. [Docs Reference](https://docs.pola.rs/user-guide/expressions/missing-data/)"
      ],
      "id": "bbfc1b1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "df_original.null_count()"
      ],
      "id": "f7a064d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling categorical variables\n",
        "\n",
        "### Outlier detection\n",
        "\n",
        "### Feature scaling\n",
        "\n",
        "\n",
        "### Datetime transformation\n",
        "\n",
        "The `ts` column is in unix seconds, which we will convert to timestamp."
      ],
      "id": "95c86378"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "df_original = df_original.with_columns(pl.from_epoch(pl.col(\"ts\"), time_unit=\"s\").alias(\"timestamp\"))\n",
        "df_original.head(2)"
      ],
      "id": "3b51aad8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### What is the date range of the data collected?\n",
        "\n",
        "The time range of the dataset is"
      ],
      "id": "f3cf9f74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "print(df_original.select(pl.col(['timestamp', 'ts'])).describe())"
      ],
      "id": "6fec9694",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Find the average humidity level across all sensors."
      ],
      "id": "1014d57b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "df_original.select(pl.col(\"humidity\").mean())"
      ],
      "id": "50728cca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove unwanted columns\n",
        "\n",
        "We are only interested in certain columns, the rest of the columns can be removed."
      ],
      "id": "450f0173"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "irrelevant_columns = [\"co\", \"lpg\", \"motion\", \"smoke\", \"ts\", \"light\"]\n",
        "for columnname in irrelevant_columns:\n",
        "    pass\n",
        "    #df = df_original.drop(columnname)\n",
        "#df_original.head(1)"
      ],
      "id": "bf707784",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reorganize the columns"
      ],
      "id": "82bb6917"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "df = df_original.select(['timestamp', 'device', 'temp', 'humidity'])\n",
        "df = df.sort(by=\"timestamp\")\n",
        "df.head(1)"
      ],
      "id": "0513e4ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import seaborn as sn\n",
        "sn.lineplot(df.head(100), x=\"timestamp\", y=\"temp\")"
      ],
      "id": "f4d603e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from prophet import Prophet\n",
        "import pandas as pd\n",
        "import dyplot\n",
        "df_device_1 = df.filter(pl.col(\"device\")==\"b8:27:eb:bf:9d:51\")\n",
        "df_device_2 = df.filter(pl.col(\"device\")==\"00:0f:00:70:91:0a\")\n",
        "df_device_3 = df.filter(pl.col(\"device\")==\"1c:bf:ce:15:ec:4d\")\n",
        "\n",
        "\n",
        "def get_forecast_data(df):\n",
        "    device_df = df.select(pl.col([\"timestamp\", \"temp\"])).rename({\"timestamp\":\"ds\", \"temp\":\"y\"})\n",
        "    device_df = device_df.to_pandas()\n",
        "    m = Prophet()\n",
        "    m.fit(device_df)\n",
        "\n",
        "    future = m.make_future_dataframe(periods=4)\n",
        "    forecast = m.predict(future)\n",
        "    forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
        "    fig = m.plot(forecast)\n",
        "    fig_comp = m.plot_components(forecast)\n",
        "    #fig_dyplot = dyplot.prophet(m, forecast)\n",
        "    #fig_dyplot.show()\n",
        "    return fig, fig_comp\n",
        "\n",
        "fig, fig_comp = get_forecast_data(df_device_1)\n",
        "fig, fig_comp = get_forecast_data(df_device_2)\n",
        "fig, fig_comp = get_forecast_data(df_device_3)"
      ],
      "id": "e5f53be4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/wslap/Documents/jeev20.github.io/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}